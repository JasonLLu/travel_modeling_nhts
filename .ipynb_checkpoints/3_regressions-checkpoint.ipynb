{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import util\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read df and images\n",
    "size = 12000\n",
    "df_ = pd.read_csv(\"data_process/df_merged_tract_large.csv\")\n",
    "df = df_.iloc[:size,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read latent vectors \n",
    "import pickle\n",
    "with open('data_process/last_layer_dic_train.pickle', 'rb') as h:\n",
    "    last_layer_dic_train = pickle.load(h)\n",
    "\n",
    "with open('data_process/last_layer_dic_test.pickle', 'rb') as h:\n",
    "    last_layer_dic_test = pickle.load(h)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression \n",
    "def Linear_eval(x_train_, x_test_, y_train_, y_test_):\n",
    "    linear_mod = sm.OLS(y_train_, x_train_)\n",
    "    linear_mod_res = linear_mod.fit()\n",
    "    # eval\n",
    "    train_mse = mean_squared_error(y_train_, linear_mod_res.predict(x_train_))\n",
    "    test_mse = mean_squared_error(y_test_, linear_mod_res.predict(x_test_))\n",
    "    train_r2 = r2_score(y_train_, linear_mod_res.predict(x_train_))\n",
    "    test_r2 = r2_score(y_test_, linear_mod_res.predict(x_test_))\n",
    "    return linear_mod_res, train_mse, test_mse, train_r2, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression with regularization\n",
    "def Linear_reg_eval(x_train_, x_test_, y_train_, y_test_, method, alpha, L1_wt):\n",
    "    linear_mod = sm.OLS(y_train_, x_train_)\n",
    "    linear_mod_res = linear_mod.fit_regularized(method=method, alpha=alpha, L1_wt=L1_wt)\n",
    "    # eval\n",
    "    train_mse = mean_squared_error(y_train_, linear_mod_res.predict(x_train_))\n",
    "    test_mse = mean_squared_error(y_test_, linear_mod_res.predict(x_test_))\n",
    "    train_r2 = r2_score(y_train_, linear_mod_res.predict(x_train_))\n",
    "    test_r2 = r2_score(y_test_, linear_mod_res.predict(x_test_))\n",
    "    return linear_mod_res, train_mse, test_mse, train_r2, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data_linear_reg(df, BE_var, output_var, input_var, last_layer_dic_train, last_layer_dic_test, size, input_structure):\n",
    "    # output: x train and test, y train and test.\n",
    "    y_ = df[output_var].values \n",
    "    y = copy.deepcopy(y_)\n",
    "    x = df[input_var]\n",
    "    BE = df[BE_var]\n",
    "    \n",
    "    # randomization. \n",
    "    shuffle_idx = np.arange(size)\n",
    "    np.random.seed(0) # Keey this seed consistent across scripts.\n",
    "    np.random.shuffle(shuffle_idx)\n",
    "    train_ratio = 0.8 # Keey this consistent across scripts.\n",
    "\n",
    "    # train test.\n",
    "    y_train = y[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "    y_test = y[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")\n",
    "    BE_train = BE.values[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "    BE_test = BE.values[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")\n",
    "    x_train = x.values[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "    x_test = x.values[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")\n",
    "    # \n",
    "    cnn_vector_train=last_layer_dic_train[output_var] \n",
    "    cnn_vector_test=last_layer_dic_test[output_var]\n",
    "    \n",
    "    if input_structure == 'BE linear':\n",
    "        x_train_ = sm.add_constant(BE_train)\n",
    "        x_test_ = sm.add_constant(BE_test)\n",
    "        y_train_ = y_train[:]\n",
    "        y_test_ = y_test[:]\n",
    "\n",
    "    elif input_structure == 'BE quadratic':\n",
    "        poly = PolynomialFeatures(2, interaction_only = False, include_bias=True)\n",
    "        x_train_ = poly.fit_transform(BE_train)\n",
    "        x_test_ = poly.fit_transform(BE_test)\n",
    "        y_train_ = y_train[:]\n",
    "        y_test_ = y_test[:]\n",
    "        \n",
    "    elif input_structure == 'NHTS linear':\n",
    "        x_train_ = sm.add_constant(x_train)\n",
    "        x_test_ = sm.add_constant(x_test)\n",
    "        y_train_ = y_train[:]\n",
    "        y_test_ = y_test[:]\n",
    "\n",
    "    elif input_structure == 'NHTS quadratic': # I have concern about its computational problem.\n",
    "        poly = PolynomialFeatures(2, interaction_only = False, include_bias=True)\n",
    "        x_train_ = poly.fit_transform(x_train)\n",
    "        x_test_ = poly.fit_transform(x_test)\n",
    "        y_train_ = y_train[:]\n",
    "        y_test_ = y_test[:]\n",
    "        \n",
    "    elif input_structure == 'BE and NHTS linear':\n",
    "        x_train_ = sm.add_constant(np.concatenate([x_train, BE_train], axis = 1))\n",
    "        x_test_ = sm.add_constant(np.concatenate([x_test, BE_test], axis = 1))\n",
    "        y_train_ = y_train[:]\n",
    "        y_test_ = y_test[:]\n",
    "        \n",
    "    elif input_structure == 'BE and NHTS quadratic': # I have concern about its computational problem. \n",
    "        poly = PolynomialFeatures(2, interaction_only = False, include_bias=True)\n",
    "        x_train_ = poly.fit_transform(np.concatenate([x_train, BE_train], axis = 1))\n",
    "        x_test_ = poly.fit_transform(np.concatenate([x_test, BE_test], axis = 1))\n",
    "        y_train_ = y_train[:]\n",
    "        y_test_ = y_test[:]\n",
    "\n",
    "    elif input_structure == 'CNN and NHTS linear':\n",
    "        x_train_ = sm.add_constant(np.concatenate([x_train, cnn_vector_train], axis = 1))\n",
    "        x_test_ = sm.add_constant(np.concatenate([x_test, cnn_vector_test], axis = 1))\n",
    "        y_train_ = y_train[:]\n",
    "        y_test_ = y_test[:]\n",
    "\n",
    "    elif input_structure == 'CNN BE NHTS linear':\n",
    "        x_train_ = sm.add_constant(np.concatenate([x_train, BE_train, cnn_vector_train], axis = 1))\n",
    "        x_test_ = sm.add_constant(np.concatenate([x_test, BE_test, cnn_vector_test], axis = 1))\n",
    "        y_train_ = y_train[:]\n",
    "        y_test_ = y_test[:]\n",
    "\n",
    "    return x_train_, x_test_, y_train_, y_test_\n",
    "    \n",
    "# # test\n",
    "# output_var = 'HHVEHCNT_mean'\n",
    "# input_var = ['R_AGE_IMP_mean', 'HHSIZE_mean', 'HHFAMINC_mean', 'HBHTNRNT_mean', 'HBPPOPDN_mean', 'HBRESDN_mean', \n",
    "#       'R_SEX_IMP_2_mean', 'EDUC_2_mean', 'HH_RACE_2_mean', 'HOMEOWN_1_mean', 'HOMEOWN_2_mean',\n",
    "#       'HBHUR_R_mean', 'HBHUR_S_mean', 'HBHUR_T_mean','HBHUR_U_mean']\n",
    "# input_structure = 'BE and NHTS quadratic'\n",
    "# x_train_, x_test_, y_train_, y_test_ = initialize_data_linear_reg(df, BE, output_var, input_var, size, input_structure)\n",
    "# print(x_train_)\n",
    "# print(y_train_)\n",
    "# print(x_train_.shape)\n",
    "# print(y_train_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "output_var_list=['HHVEHCNT_mean_norm', 'HHVEHCNT_P_CAP_mean_norm', 'TRPTRANS_1_mean_norm', 'TRPTRANS_2_mean_norm', 'TRPTRANS_3_mean_norm']\n",
    "# input_var=['R_AGE_IMP_mean', \n",
    "#            'HBHUR_R_mean', 'HBHUR_S_mean']\n",
    "input_var=['R_AGE_IMP_mean', 'HHSIZE_mean', 'HHFAMINC_mean', 'HBHTNRNT_mean', 'HBPPOPDN_mean', 'HBRESDN_mean', \n",
    "           'R_SEX_IMP_2_mean', 'EDUC_2_mean', 'HH_RACE_2_mean', 'HOMEOWN_1_mean', 'HOMEOWN_2_mean',\n",
    "           'HBHUR_R_mean', 'HBHUR_S_mean', 'HBHUR_T_mean','HBHUR_U_mean']\n",
    "BE_var = ['density', 'diversity', 'design']\n",
    "input_structure_list = ['BE linear', 'BE quadratic', 'NHTS linear', 'NHTS quadratic', 'BE and NHTS linear', 'BE and NHTS quadratic']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   270.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 Jun 2020</td> <th>  Prob (F-statistic):</th> <td>2.12e-168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:07:00</td>     <th>  Log-Likelihood:    </th> <td> -13753.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  9600</td>      <th>  AIC:               </th> <td>2.751e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9596</td>      <th>  BIC:               </th> <td>2.754e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.3595</td> <td>    0.019</td> <td>   19.121</td> <td> 0.000</td> <td>    0.323</td> <td>    0.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.5548</td> <td>    0.077</td> <td>   -7.200</td> <td> 0.000</td> <td>   -0.706</td> <td>   -0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.1004</td> <td>    0.033</td> <td>   -3.005</td> <td> 0.003</td> <td>   -0.166</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -1.1654</td> <td>    0.086</td> <td>  -13.615</td> <td> 0.000</td> <td>   -1.333</td> <td>   -0.998</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3643.110</td> <th>  Durbin-Watson:     </th> <td>   2.020</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>26910.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.634</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.523</td>  <th>  Cond. No.          </th> <td>    11.6</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.078\n",
       "Model:                            OLS   Adj. R-squared:                  0.078\n",
       "Method:                 Least Squares   F-statistic:                     270.3\n",
       "Date:                Thu, 25 Jun 2020   Prob (F-statistic):          2.12e-168\n",
       "Time:                        20:07:00   Log-Likelihood:                -13753.\n",
       "No. Observations:                9600   AIC:                         2.751e+04\n",
       "Df Residuals:                    9596   BIC:                         2.754e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.3595      0.019     19.121      0.000       0.323       0.396\n",
       "x1            -0.5548      0.077     -7.200      0.000      -0.706      -0.404\n",
       "x2            -0.1004      0.033     -3.005      0.003      -0.166      -0.035\n",
       "x3            -1.1654      0.086    -13.615      0.000      -1.333      -0.998\n",
       "==============================================================================\n",
       "Omnibus:                     3643.110   Durbin-Watson:                   2.020\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            26910.709\n",
       "Skew:                           1.634   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.523   Cond. No.                         11.6\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one example regression.\n",
    "output_var = \"HHVEHCNT_mean_norm\"\n",
    "input_structure = 'BE linear'\n",
    "x_train_, x_test_, y_train_, y_test_ = initialize_data_linear_reg(df, BE_var, output_var, input_var, last_layer_dic_train, last_layer_dic_test, size, input_structure)\n",
    "linear_mod_res, train_mse, test_mse, train_r2, test_r2 = Linear_eval(x_train_, x_test_, y_train_, y_test_)\n",
    "linear_mod_res.summary()\n",
    "# Note: results show that 3Ds are very significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "HHVEHCNT_mean_norm\n",
      "BE linear\n",
      "BE quadratic\n",
      "NHTS linear\n",
      "NHTS quadratic\n",
      "BE and NHTS linear\n",
      "BE and NHTS quadratic\n",
      "-----\n",
      "HHVEHCNT_P_CAP_mean_norm\n",
      "BE linear\n",
      "BE quadratic\n",
      "NHTS linear\n",
      "NHTS quadratic\n",
      "BE and NHTS linear\n",
      "BE and NHTS quadratic\n",
      "-----\n",
      "TRPTRANS_1_mean_norm\n",
      "BE linear\n",
      "BE quadratic\n",
      "NHTS linear\n",
      "NHTS quadratic\n",
      "BE and NHTS linear\n",
      "BE and NHTS quadratic\n",
      "-----\n",
      "TRPTRANS_2_mean_norm\n",
      "BE linear\n",
      "BE quadratic\n",
      "NHTS linear\n",
      "NHTS quadratic\n",
      "BE and NHTS linear\n",
      "BE and NHTS quadratic\n",
      "-----\n",
      "TRPTRANS_3_mean_norm\n",
      "BE linear\n",
      "BE quadratic\n",
      "NHTS linear\n",
      "NHTS quadratic\n",
      "BE and NHTS linear\n",
      "BE and NHTS quadratic\n"
     ]
    }
   ],
   "source": [
    "# iterate over models.\n",
    "performance_handcrafted = {}\n",
    "\n",
    "for output_var in output_var_list:\n",
    "    print(\"-----\")\n",
    "    print(output_var)\n",
    "    performance_handcrafted[output_var] = {}\n",
    "\n",
    "    for input_structure in input_structure_list:\n",
    "        print(input_structure)\n",
    "        x_train_, x_test_, y_train_, y_test_ = initialize_data_linear_reg(df, BE_var, output_var, input_var, last_layer_dic_train, last_layer_dic_test, size, input_structure)\n",
    "        linear_mod_res, train_mse, test_mse, train_r2, test_r2 = Linear_eval(x_train_, x_test_, y_train_, y_test_)\n",
    "        # save models\n",
    "        linear_mod_res.save(\"models/\"+output_var+\"_\"+input_structure+\".pickle\")\n",
    "        # save\n",
    "        performance_handcrafted[output_var][input_structure] = {}\n",
    "        performance_handcrafted[output_var][input_structure]['train_mse']=train_mse\n",
    "        performance_handcrafted[output_var][input_structure]['test_mse']=test_mse\n",
    "        performance_handcrafted[output_var][input_structure]['train_r2']=train_r2\n",
    "        performance_handcrafted[output_var][input_structure]['test_r2']=test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('outputs/performance_handcrafted.pickle', 'wb') as h:\n",
    "    pickle.dump(performance_handcrafted, h, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHVEHCNT_mean_norm</th>\n",
       "      <th>HHVEHCNT_P_CAP_mean_norm</th>\n",
       "      <th>TRPTRANS_1_mean_norm</th>\n",
       "      <th>TRPTRANS_2_mean_norm</th>\n",
       "      <th>TRPTRANS_3_mean_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>BE linear</td>\n",
       "      <td>0.084195</td>\n",
       "      <td>0.087349</td>\n",
       "      <td>0.178908</td>\n",
       "      <td>0.222090</td>\n",
       "      <td>0.110670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BE quadratic</td>\n",
       "      <td>0.094053</td>\n",
       "      <td>0.094257</td>\n",
       "      <td>0.223722</td>\n",
       "      <td>0.275076</td>\n",
       "      <td>0.126030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NHTS linear</td>\n",
       "      <td>0.341971</td>\n",
       "      <td>0.337261</td>\n",
       "      <td>0.318877</td>\n",
       "      <td>0.382529</td>\n",
       "      <td>0.169336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NHTS quadratic</td>\n",
       "      <td>0.365544</td>\n",
       "      <td>0.367325</td>\n",
       "      <td>0.317638</td>\n",
       "      <td>0.382133</td>\n",
       "      <td>0.147775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BE and NHTS linear</td>\n",
       "      <td>0.343357</td>\n",
       "      <td>0.338454</td>\n",
       "      <td>0.319964</td>\n",
       "      <td>0.385261</td>\n",
       "      <td>0.173725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BE and NHTS quadratic</td>\n",
       "      <td>0.366108</td>\n",
       "      <td>0.367583</td>\n",
       "      <td>0.323204</td>\n",
       "      <td>0.399684</td>\n",
       "      <td>0.173483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       HHVEHCNT_mean_norm  HHVEHCNT_P_CAP_mean_norm  \\\n",
       "BE linear                        0.084195                  0.087349   \n",
       "BE quadratic                     0.094053                  0.094257   \n",
       "NHTS linear                      0.341971                  0.337261   \n",
       "NHTS quadratic                   0.365544                  0.367325   \n",
       "BE and NHTS linear               0.343357                  0.338454   \n",
       "BE and NHTS quadratic            0.366108                  0.367583   \n",
       "\n",
       "                       TRPTRANS_1_mean_norm  TRPTRANS_2_mean_norm  \\\n",
       "BE linear                          0.178908              0.222090   \n",
       "BE quadratic                       0.223722              0.275076   \n",
       "NHTS linear                        0.318877              0.382529   \n",
       "NHTS quadratic                     0.317638              0.382133   \n",
       "BE and NHTS linear                 0.319964              0.385261   \n",
       "BE and NHTS quadratic              0.323204              0.399684   \n",
       "\n",
       "                       TRPTRANS_3_mean_norm  \n",
       "BE linear                          0.110670  \n",
       "BE quadratic                       0.126030  \n",
       "NHTS linear                        0.169336  \n",
       "NHTS quadratic                     0.147775  \n",
       "BE and NHTS linear                 0.173725  \n",
       "BE and NHTS quadratic              0.173483  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only test r2 for analysis\n",
    "performance_handcrafted_r2_test = {}\n",
    "for output_var_key in performance_handcrafted.keys():\n",
    "    performance_handcrafted_r2_test[output_var_key]={}\n",
    "    for input_structure_key in performance_handcrafted[output_var_key].keys():\n",
    "        performance_handcrafted_r2_test[output_var_key][input_structure_key]=\\\n",
    "            performance_handcrafted[output_var_key][input_structure_key]['test_r2']\n",
    "\n",
    "r2_test_table = pd.DataFrame(performance_handcrafted_r2_test)\n",
    "r2_test_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine extracted ResNet layers with NHTS data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "HHVEHCNT_mean_norm\n",
      "CNN and NHTS linear\n",
      "CNN BE NHTS linear\n",
      "-----\n",
      "HHVEHCNT_P_CAP_mean_norm\n",
      "CNN and NHTS linear\n",
      "CNN BE NHTS linear\n",
      "-----\n",
      "TRPTRANS_1_mean_norm\n",
      "CNN and NHTS linear\n",
      "CNN BE NHTS linear\n",
      "-----\n",
      "TRPTRANS_2_mean_norm\n",
      "CNN and NHTS linear\n",
      "CNN BE NHTS linear\n",
      "-----\n",
      "TRPTRANS_3_mean_norm\n",
      "CNN and NHTS linear\n",
      "CNN BE NHTS linear\n"
     ]
    }
   ],
   "source": [
    "# Train two other input structures.\n",
    "# total models: 5 * 2 * 5 * 5 = 250 models.\n",
    "# This part needs to be refined. Ideally we still need train/val/testing sets. \n",
    "method = 'elastic_net'\n",
    "\n",
    "alpha_list = [10.0, 1.0, 0.1, 0.01, 0.001]\n",
    "L1_wt_list = [0.01, 0.1, 0.5, 0.9, 0.99]\n",
    "input_structure_list = ['CNN and NHTS linear', 'CNN BE NHTS linear']\n",
    "\n",
    "performance_cnn_combined = {}\n",
    "hyper_param_dic = {}\n",
    "\n",
    "for output_var in output_var_list:\n",
    "    print(\"-----\")\n",
    "    print(output_var)\n",
    "    performance_cnn_combined[output_var] = {}\n",
    "    hyper_param_dic[output_var]={}\n",
    "\n",
    "    for input_structure in input_structure_list:\n",
    "        print(input_structure)\n",
    "        \n",
    "        performance_cnn_combined[output_var][input_structure]={}\n",
    "        hyper_param_dic[output_var][input_structure]={}\n",
    "        \n",
    "        x_train_, x_test_, y_train_, y_test_ = initialize_data_linear_reg(df, BE_var, output_var, input_var, last_layer_dic_train, last_layer_dic_test, size, input_structure)\n",
    "            \n",
    "        # search a bit. It takes a while...\n",
    "        best_train_mse=0.0\n",
    "        best_test_mse=0.0\n",
    "        best_train_r2=0.0\n",
    "        best_test_r2=0.0\n",
    "        hyper_param_dic[output_var][input_structure]['alpha']=0.0\n",
    "        hyper_param_dic[output_var][input_structure]['L1_wt']=0.0\n",
    "\n",
    "        # search 5*5=25 models\n",
    "        for alpha in alpha_list:\n",
    "            for L1_wt in L1_wt_list:\n",
    "                linear_mod_res, train_mse, test_mse, train_r2, test_r2 = Linear_reg_eval(x_train_, x_test_, y_train_, y_test_, method, alpha, L1_wt)\n",
    "                \n",
    "                if test_r2 > best_test_r2:\n",
    "                    best_train_mse=train_mse\n",
    "                    best_test_mse=test_mse\n",
    "                    best_train_r2=train_r2\n",
    "                    best_test_r2=test_r2\n",
    "                    hyper_param_dic[output_var][input_structure]['alpha']=alpha\n",
    "                    hyper_param_dic[output_var][input_structure]['L1_wt']=L1_wt\n",
    "                    \n",
    "        performance_cnn_combined[output_var][input_structure]['train_mse']=best_train_mse\n",
    "        performance_cnn_combined[output_var][input_structure]['test_mse']=best_test_mse\n",
    "        performance_cnn_combined[output_var][input_structure]['train_r2']=best_train_r2\n",
    "        performance_cnn_combined[output_var][input_structure]['test_r2']=best_test_r2\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HHVEHCNT_mean_norm': {'CNN and NHTS linear': {'alpha': 0.01, 'L1_wt': 0.9}, 'CNN BE NHTS linear': {'alpha': 0.01, 'L1_wt': 0.9}}, 'HHVEHCNT_P_CAP_mean_norm': {'CNN and NHTS linear': {'alpha': 0.001, 'L1_wt': 0.99}, 'CNN BE NHTS linear': {'alpha': 0.001, 'L1_wt': 0.99}}, 'TRPTRANS_1_mean_norm': {'CNN and NHTS linear': {'alpha': 0.1, 'L1_wt': 0.1}, 'CNN BE NHTS linear': {'alpha': 0.1, 'L1_wt': 0.1}}, 'TRPTRANS_2_mean_norm': {'CNN and NHTS linear': {'alpha': 0.001, 'L1_wt': 0.9}, 'CNN BE NHTS linear': {'alpha': 0.01, 'L1_wt': 0.1}}, 'TRPTRANS_3_mean_norm': {'CNN and NHTS linear': {'alpha': 0.01, 'L1_wt': 0.5}, 'CNN BE NHTS linear': {'alpha': 0.01, 'L1_wt': 0.5}}}\n"
     ]
    }
   ],
   "source": [
    "print(hyper_param_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('outputs/performance_cnn_combined.pickle', 'wb') as h:\n",
    "    pickle.dump(performance_cnn_combined, h, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHVEHCNT_mean_norm</th>\n",
       "      <th>HHVEHCNT_P_CAP_mean_norm</th>\n",
       "      <th>TRPTRANS_1_mean_norm</th>\n",
       "      <th>TRPTRANS_2_mean_norm</th>\n",
       "      <th>TRPTRANS_3_mean_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>CNN and NHTS linear</td>\n",
       "      <td>0.339674</td>\n",
       "      <td>0.340317</td>\n",
       "      <td>0.336230</td>\n",
       "      <td>0.415407</td>\n",
       "      <td>0.188260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CNN BE NHTS linear</td>\n",
       "      <td>0.339674</td>\n",
       "      <td>0.340322</td>\n",
       "      <td>0.336211</td>\n",
       "      <td>0.415915</td>\n",
       "      <td>0.188249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     HHVEHCNT_mean_norm  HHVEHCNT_P_CAP_mean_norm  \\\n",
       "CNN and NHTS linear            0.339674                  0.340317   \n",
       "CNN BE NHTS linear             0.339674                  0.340322   \n",
       "\n",
       "                     TRPTRANS_1_mean_norm  TRPTRANS_2_mean_norm  \\\n",
       "CNN and NHTS linear              0.336230              0.415407   \n",
       "CNN BE NHTS linear               0.336211              0.415915   \n",
       "\n",
       "                     TRPTRANS_3_mean_norm  \n",
       "CNN and NHTS linear              0.188260  \n",
       "CNN BE NHTS linear               0.188249  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only test r2 for analysis \n",
    "performance_cnn_combined_r2_test = {}\n",
    "for output_var_key in performance_cnn_combined.keys():\n",
    "    performance_cnn_combined_r2_test[output_var_key]={}\n",
    "    for input_structure_key in performance_cnn_combined[output_var_key].keys():\n",
    "        performance_cnn_combined_r2_test[output_var_key][input_structure_key]=\\\n",
    "            performance_cnn_combined[output_var_key][input_structure_key]['test_r2']\n",
    "\n",
    "r2_test_table = pd.DataFrame(performance_cnn_combined_r2_test)\n",
    "r2_test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
