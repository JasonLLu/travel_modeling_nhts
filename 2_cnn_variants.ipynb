{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Variants (Not Done Yet)\n",
    "Merge ResNet and Linear regression in one architecture to combine NHTS and Images. The training result is very bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import util\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS choose devise first.\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is exactly the same as 2_cnn initialize_data\n",
    "def initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size):\n",
    "    # inputs: image_list, output_var, output_type.\n",
    "    # outputs: data loader for training and testing.\n",
    "    \n",
    "    ### read image array\n",
    "    if image_type == 'rgb':\n",
    "        image_array_ = np.load(\"../data_process/image_array_rgb_tract_large.npy\", mmap_mode='r')\n",
    "        image_array = image_array_[:size,]\n",
    "    elif image_type == 'bw':\n",
    "        image_array_ = np.load(\"../data_process/image_array_bw_tract_large.npy\", mmap_mode='r')\n",
    "        image_array = image_array_[:size,]        \n",
    "    elif image_type == 'merge':\n",
    "        bw_image_array_ = np.load(\"../data_process/image_array_bw_tract_large.npy\", mmap_mode='r')\n",
    "        rgb_image_array_ = np.load(\"../data_process/image_array_rgb_tract_large.npy\", mmap_mode='r')\n",
    "        bw_image_array = bw_image_array_[:size,]\n",
    "        rgb_image_array = rgb_image_array_[:size,]\n",
    "        image_array = np.concatenate([rgb_image_array, bw_image_array], axis=1)\n",
    "    \n",
    "    ### create output array\n",
    "    df_ = pd.read_csv(\"../data_process/df_merged_tract_large.csv\")\n",
    "    df = df_.iloc[:size,]\n",
    "    y_ = df[output_var].values \n",
    "    # cut y into categories for discrete variables\n",
    "    if output_type == 'continuous':\n",
    "        y = copy.deepcopy(y_)\n",
    "    elif output_type == 'discrete':\n",
    "        y = np.array(pd.qcut(y_, q = num_categories, labels=np.arange(num_categories))) \n",
    "    x = df[input_var]\n",
    "    BE = df[BE_var]\n",
    "            \n",
    "    ### randomization\n",
    "    shuffle_idx = np.arange(size)\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(shuffle_idx)\n",
    "    train_ratio = 0.8\n",
    "\n",
    "    ###\n",
    "    # y\n",
    "    if output_type == 'discrete':\n",
    "        y_train = y[shuffle_idx[:int(train_ratio*size)]].astype(\"int\")\n",
    "        y_test = y[shuffle_idx[int(train_ratio*size):]].astype(\"int\")\n",
    "    elif output_type == 'continuous':\n",
    "        y_train = y[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "        y_test = y[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")\n",
    "    # BE\n",
    "    BE_train = BE.values[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "    BE_test = BE.values[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")        \n",
    "    # image array\n",
    "    x_train_images = image_array[shuffle_idx[:int(train_ratio*size)],].astype(\"float32\")\n",
    "    x_test_images = image_array[shuffle_idx[int(train_ratio*size):],].astype(\"float32\")\n",
    "    # NHTS\n",
    "    x_train = x.values[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "    x_test = x.values[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")\n",
    "    \n",
    "    return y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_categories=1\n",
    "num_bottleneck=1\n",
    "model = bottleneck_resnet18(num_categories, num_bottleneck)\n",
    "\n",
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: combine resnet and linear\n",
    "class ResNet_And_Linear(nn.Module):\n",
    "    def __init__(self, num_categories, num_x_nhts, input_channels = 3, use_pretrained=True, full_training=True):\n",
    "        super(ResNet_And_Linear, self).__init__()\n",
    "        # resnet branch\n",
    "        self.resnet_branch = models.resnet18(pretrained=use_pretrained)\n",
    "        for param in self.resnet_branch.parameters():\n",
    "            param.requires_grad=full_training\n",
    "        if input_channels != 3:\n",
    "            self.resnet_branch.conv1 = nn.Conv2d(input_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        num_ftrs = self.resnet_branch.fc.in_features\n",
    "        self.resnet_branch.fc = nn.Linear(num_ftrs, num_categories)\n",
    "        # linear branch\n",
    "        self.linear_branch = nn.Linear(num_x_nhts, num_categories)\n",
    "    \n",
    "    def forward(self, x_images, x_nhts):\n",
    "        y_from_images = self.resnet_branch(x_images)\n",
    "        y_from_nhts = self.linear_branch(x_nhts)\n",
    "        y = y_from_images + y_from_nhts\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is quite similar to 2_cnn initialize_data\n",
    "def train_continuous_merged_model(model, train_dl, test_dl, criterion, optimizer, device, total_mse_train, total_mse_test, n_epoch = 25):\n",
    "    mse_train_list = []\n",
    "    mse_test_list = []\n",
    "    r_square_train_list = []\n",
    "    r_square_test_list = []\n",
    "\n",
    "    # automatic model searching.\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_r_square = 0.0\n",
    "    \n",
    "    for epoch in range(n_epoch): # loop over the dataset multiple times\n",
    "        running_mse_train = 0.0\n",
    "        running_mse_test = 0.0\n",
    "        \n",
    "        # training\n",
    "        for x_train_images_batch, x_train_nhts_batch, y_train_batch in train_dl:\n",
    "            # to device\n",
    "            x_train_images_batch = x_train_images_batch.to(device)\n",
    "            x_train_nhts_batch = x_train_nhts_batch.to(device)\n",
    "            y_train_batch = y_train_batch.to(device)\n",
    "\n",
    "            # forward + backward\n",
    "            outputs = model(x_train_images_batch, x_train_nhts_batch)\n",
    "            # sw: be careful about the dimension matching at this point...\n",
    "            loss = criterion(outputs.view(-1), y_train_batch) # this .view(-1) seems specific to continuous variables\n",
    "            loss.backward()\n",
    "\n",
    "            # statistics\n",
    "            running_mse_train += loss.item()*batch_size\n",
    "\n",
    "            # optimize\n",
    "            with torch.no_grad():\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # testing\n",
    "        for x_test_images_batch, x_test_nhts_batch, y_test_batch in test_dl:\n",
    "            # to device\n",
    "            x_test_images_batch = x_test_images_batch.to(device)\n",
    "            x_test_nhts_batch = x_test_nhts_batch.to(device)\n",
    "            y_test_batch = y_test_batch.to(device)\n",
    "\n",
    "            # forward + backward\n",
    "            outputs = model(x_test_images_batch, x_test_nhts_batch)\n",
    "            loss = criterion(outputs.view(-1), y_test_batch) # this .view(-1) seems specific to continuous variables\n",
    "            running_mse_test += loss.item()*batch_size # this *batch_size is specific to continuous variables.\n",
    "\n",
    "        running_r_square_train = 1-running_mse_train/total_mse_train.item()\n",
    "        running_r_square_test = 1-running_mse_test/total_mse_test.item()\n",
    "        \n",
    "        print(\"Epoch {}: Training MSE {}; Testing MSE {}\".format(epoch, running_mse_train, running_mse_test))\n",
    "        print(\"Epoch {}: Training R2 {}; Testing R2 {}\".format(epoch, running_r_square_train, running_r_square_test))\n",
    "\n",
    "        mse_train_list.append(running_mse_train)\n",
    "        mse_test_list.append(running_mse_test)\n",
    "        r_square_train_list.append(running_r_square_train)\n",
    "        r_square_test_list.append(running_r_square_test)\n",
    "\n",
    "        # check overfitting for early stopping.\n",
    "        #if epoch > 5 and running_r_square_test < 0.0:\n",
    "        #    break # break the for loop.\n",
    "        \n",
    "        # replace the model with the best performance.\n",
    "        if running_r_square_test > best_r_square:\n",
    "            best_r_square = running_r_square_test\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # load the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, mse_train_list, mse_test_list, r_square_train_list, r_square_test_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "output_list = ['HHVEHCNT_mean_norm', 'HHVEHCNT_P_CAP_mean_norm', 'TRPTRANS_1_mean_norm', 'TRPTRANS_2_mean_norm', 'TRPTRANS_3_mean_norm']\n",
    "input_var=['R_AGE_IMP_mean', 'HHSIZE_mean', 'HHFAMINC_mean', 'HBHTNRNT_mean', 'HBPPOPDN_mean', 'HBRESDN_mean', \n",
    "           'R_SEX_IMP_2_mean', 'EDUC_2_mean', 'HH_RACE_2_mean', 'HOMEOWN_1_mean', 'HOMEOWN_2_mean',\n",
    "           'HBHUR_R_mean', 'HBHUR_S_mean', 'HBHUR_T_mean','HBHUR_U_mean']\n",
    "BE_var = ['density', 'diversity', 'design']\n",
    "image_type = 'bw' # 'rgb', 'bw'\n",
    "output_type = 'continuous'\n",
    "num_categories = 1 # (1) certain category values can cause errors. (2) when output_type = 'continuous', this value needs to be 1.\n",
    "size = 12000 # size needs to be smaller than the max (18491)\n",
    "\n",
    "# output_var = 'TRPTRANS_1_mean_norm'\n",
    "\n",
    "performance = {}\n",
    "model_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HHVEHCNT_mean_norm\n",
      "tensor(10700.4521)\n",
      "tensor(2549.4304)\n",
      "Epoch 0: Training MSE 4961943844.433594; Testing MSE 220687191.015625\n",
      "Epoch 0: Training R2 -463712.4744963227; Testing R2 -86562.33167248697\n",
      "Epoch 1: Training MSE 470774952.734375; Testing MSE 88693916.796875\n",
      "Epoch 1: Training R2 -43994.80000954618; Testing R2 -34788.698947576275\n",
      "Epoch 2: Training MSE 297294765.9667969; Testing MSE 66993853.515625\n",
      "Epoch 2: Training R2 -27782.3835283501; Testing R2 -26276.96898951177\n",
      "Epoch 3: Training MSE 230535849.75585938; Testing MSE 54315483.7890625\n",
      "Epoch 3: Training R2 -21543.496116411552; Testing R2 -21303.94849540822\n",
      "Epoch 4: Training MSE 170203946.6796875; Testing MSE 37459639.0625\n",
      "Epoch 4: Training R2 -15905.238756886642; Testing R2 -14692.336507551328\n",
      "Epoch 5: Training MSE 121546618.01757812; Testing MSE 25528741.430664062\n",
      "Epoch 5: Training R2 -11358.017014559202; Testing R2 -10012.507813814495\n",
      "Epoch 6: Training MSE 88242155.22460938; Testing MSE 20932307.91015625\n",
      "Epoch 6: Training R2 -8245.581920138267; Testing R2 -8209.582154580905\n",
      "Epoch 7: Training MSE 63029529.85839844; Testing MSE 14701022.277832031\n",
      "Epoch 7: Training R2 -5889.361358945203; Testing R2 -5765.3947848721955\n",
      "Epoch 8: Training MSE 43651955.432128906; Testing MSE 11189313.427734375\n",
      "Epoch 8: Training R2 -4078.449618257771; Testing R2 -4387.946385945007\n",
      "Epoch 9: Training MSE 31224270.20263672; Testing MSE 7637653.1005859375\n",
      "Epoch 9: Training R2 -2917.032786791738; Testing R2 -2994.8272408234566\n",
      "Epoch 10: Training MSE 20017062.365722656; Testing MSE 5469032.736206055\n",
      "Epoch 10: Training R2 -1869.6744432893506; Testing R2 -2144.1978816404207\n",
      "Epoch 11: Training MSE 14423050.686645508; Testing MSE 3988911.7248535156\n",
      "Epoch 11: Training R2 -1346.8917046277888; Testing R2 -1563.6285906385915\n",
      "Epoch 12: Training MSE 10066035.39428711; Testing MSE 2929653.1005859375\n",
      "Epoch 12: Training R2 -939.71121992326; Testing R2 -1148.1402462655615\n",
      "Epoch 13: Training MSE 6936943.09387207; Testing MSE 2209683.090209961\n",
      "Epoch 13: Training R2 -647.2850441871295; Testing R2 -865.7359865729046\n",
      "Epoch 14: Training MSE 4931598.8037109375; Testing MSE 1697151.220703125\n",
      "Epoch 14: Training R2 -459.87760921682724; Testing R2 -664.6981918161675\n",
      "Epoch 15: Training MSE 3368467.5048828125; Testing MSE 1226240.0177001953\n",
      "Epoch 15: Training R2 -313.7967448622891; Testing R2 -479.9858735967277\n",
      "Epoch 16: Training MSE 2419292.0692443848; Testing MSE 983714.4607543945\n",
      "Epoch 16: Training R2 -225.0925085859717; Testing R2 -384.8565635160734\n",
      "Epoch 17: Training MSE 1855504.653930664; Testing MSE 710024.6383666992\n",
      "Epoch 17: Training R2 -172.40432237731267; Testing R2 -277.5032424569788\n",
      "Epoch 18: Training MSE 1278359.2224121094; Testing MSE 544936.3746643066\n",
      "Epoch 18: Training R2 -118.46777619100682; Testing R2 -212.7482829129362\n",
      "Epoch 19: Training MSE 911280.9211730957; Testing MSE 378348.36349487305\n",
      "Epoch 19: Training R2 -84.16284251653447; Testing R2 -147.40505570905802\n",
      "Epoch 20: Training MSE 707281.2446594238; Testing MSE 281358.77571105957\n",
      "Epoch 20: Training R2 -65.09825779770459; Testing R2 -109.36142563941068\n",
      "Epoch 21: Training MSE 527260.3397369385; Testing MSE 212864.10598754883\n",
      "Epoch 21: Training R2 -48.274585075727856; Testing R2 -82.4947697823704\n",
      "Epoch 22: Training MSE 412653.34701538086; Testing MSE 156257.65075683594\n",
      "Epoch 22: Training R2 -37.56410376786155; Testing R2 -60.29120039354685\n",
      "Epoch 23: Training MSE 315213.37451934814; Testing MSE 125276.41582489014\n",
      "Epoch 23: Training R2 -28.457949079785024; Testing R2 -48.13898212163371\n",
      "Epoch 24: Training MSE 247826.27687454224; Testing MSE 97280.09872436523\n",
      "Epoch 24: Training R2 -22.160355603359275; Testing R2 -37.157581381391964\n",
      "HHVEHCNT_P_CAP_mean_norm\n",
      "tensor(10708.8994)\n",
      "tensor(2445.9663)\n",
      "Epoch 0: Training MSE 7448529385.9375; Testing MSE 405811290.625\n",
      "Epoch 0: Training R2 -695544.7417179947; Testing R2 -165909.4171628233\n",
      "Epoch 1: Training MSE 815821845.1171875; Testing MSE 135783837.6953125\n",
      "Epoch 1: Training R2 -76180.67036342528; Testing R2 -55512.372043696785\n",
      "Epoch 2: Training MSE 462760341.015625; Testing MSE 103435210.546875\n",
      "Epoch 2: Training R2 -43211.6891030414; Testing R2 -42287.07657058147\n",
      "Epoch 3: Training MSE 356463832.91015625; Testing MSE 80476927.24609375\n",
      "Epoch 3: Training R2 -33285.69166899281; Testing R2 -32900.8952400706\n",
      "Epoch 4: Training MSE 284706156.73828125; Testing MSE 62648600.29296875\n",
      "Epoch 4: Training R2 -26584.939948639025; Testing R2 -25612.02666878804\n",
      "Epoch 5: Training MSE 218247167.72460938; Testing MSE 49256775.09765625\n",
      "Epoch 5: Training R2 -20378.981105996372; Testing R2 -20136.9613957051\n",
      "Epoch 6: Training MSE 167716578.22265625; Testing MSE 36225420.3125\n",
      "Epoch 6: Training R2 -15660.420631369227; Testing R2 -14809.269538555885\n",
      "Epoch 7: Training MSE 127328766.796875; Testing MSE 28064087.01171875\n",
      "Epoch 7: Training R2 -11888.995589058568; Testing R2 -11472.619613286304\n",
      "Epoch 8: Training MSE 92509440.625; Testing MSE 20528494.82421875\n",
      "Epoch 8: Training R2 -8637.557245529852; Testing R2 -8391.79541672065\n",
      "Epoch 9: Training MSE 67561357.91015625; Testing MSE 14893567.797851562\n",
      "Epoch 9: Training R2 -6307.898356206182; Testing R2 -6088.032275515791\n",
      "Epoch 10: Training MSE 47534856.201171875; Testing MSE 11316436.9140625\n",
      "Epoch 10: Training R2 -4437.818067405788; Testing R2 -4625.571050591705\n",
      "Epoch 11: Training MSE 33774609.533691406; Testing MSE 7808251.2939453125\n",
      "Epoch 11: Training R2 -3152.8824138491705; Testing R2 -3191.2971573694654\n",
      "Epoch 12: Training MSE 22590261.60888672; Testing MSE 6213099.621582031\n",
      "Epoch 12: Training R2 -2108.4848999349165; Testing R2 -2539.1411293985093\n",
      "Epoch 13: Training MSE 15462953.033447266; Testing MSE 4621392.840576172\n",
      "Epoch 13: Training R2 -1442.9348466698577; Testing R2 -1888.3934983238307\n",
      "Epoch 14: Training MSE 10423121.417236328; Testing MSE 3597855.9509277344\n",
      "Epoch 14: Training R2 -972.3139713264185; Testing R2 -1469.934386253356\n",
      "Epoch 15: Training MSE 7300246.02355957; Testing MSE 2754372.2595214844\n",
      "Epoch 15: Training R2 -680.6990001767294; Testing R2 -1125.0875711346348\n",
      "Epoch 16: Training MSE 4915003.033447266; Testing MSE 2233168.9025878906\n",
      "Epoch 16: Training R2 -457.9643476334346; Testing R2 -912.0006798302131\n",
      "Epoch 17: Training MSE 3450718.5485839844; Testing MSE 1766423.974609375\n",
      "Epoch 17: Training R2 -321.2290559618702; Testing R2 -721.178375230744\n",
      "Epoch 18: Training MSE 2572736.8927001953; Testing MSE 1610321.8994140625\n",
      "Epoch 18: Training R2 -239.2428852139352; Testing R2 -657.3581686126653\n",
      "Epoch 19: Training MSE 1864592.8504943848; Testing MSE 1367032.0678710938\n",
      "Epoch 19: Training R2 -173.1161979769719; Testing R2 -557.8924357085835\n",
      "Epoch 20: Training MSE 1412914.5614624023; Testing MSE 1145582.0770263672\n",
      "Epoch 20: Training R2 -130.9383539644624; Testing R2 -467.35562411527746\n",
      "Epoch 21: Training MSE 1093580.5278778076; Testing MSE 1073437.4114990234\n",
      "Epoch 21: Training R2 -101.1188532634606; Testing R2 -437.8602605553347\n",
      "Epoch 22: Training MSE 915130.2501678467; Testing MSE 984141.8090820312\n",
      "Epoch 22: Training R2 -84.4551167943677; Testing R2 -401.3529701224054\n",
      "Epoch 23: Training MSE 781899.5609283447; Testing MSE 900700.4348754883\n",
      "Epoch 23: Training R2 -72.01399804928464; Testing R2 -367.23910113190584\n",
      "Epoch 24: Training MSE 641313.4460449219; Testing MSE 851670.7748413086\n",
      "Epoch 24: Training R2 -58.88602761575803; Testing R2 -347.19399263555533\n",
      "TRPTRANS_1_mean_norm\n",
      "tensor(11639.5127)\n",
      "tensor(3039.0168)\n",
      "Epoch 0: Training MSE 1413568249.8046875; Testing MSE 221148046.484375\n",
      "Epoch 0: Training R2 -121444.65557061198; Testing R2 -72768.60204977372\n",
      "Epoch 1: Training MSE 575823286.71875; Testing MSE 93363068.75\n",
      "Epoch 1: Training R2 -49470.42563370778; Testing R2 -30720.471281742422\n",
      "Epoch 2: Training MSE 248882625.1953125; Testing MSE 40267216.2109375\n",
      "Epoch 2: Training R2 -21381.564005067263; Testing R2 -13249.079961837473\n",
      "Epoch 3: Training MSE 114556357.66601562; Testing MSE 19302113.989257812\n",
      "Epoch 3: Training R2 -9841.023516341033; Testing R2 -6350.433693613489\n",
      "Epoch 4: Training MSE 51709638.03100586; Testing MSE 8009121.6552734375\n",
      "Epoch 4: Training R2 -4441.594753286408; Testing R2 -2634.431806374341\n",
      "Epoch 5: Training MSE 21298248.44970703; Testing MSE 3515014.3188476562\n",
      "Epoch 5: Training R2 -1828.8230353135255; Testing R2 -1155.628770853161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training MSE 8975443.963623047; Testing MSE 1399000.8483886719\n",
      "Epoch 6: Training R2 -770.1185337885894; Testing R2 -459.34652633358166\n",
      "Epoch 7: Training MSE 3368391.6427612305; Testing MSE 528622.5921630859\n",
      "Epoch 7: Training R2 -288.39284065713156; Testing R2 -172.94526552575942\n",
      "Epoch 8: Training MSE 1310119.18258667; Testing MSE 200173.72665405273\n",
      "Epoch 8: Training R2 -111.55790657922347; Testing R2 -64.86792269252439\n",
      "Epoch 9: Training MSE 555497.3907470703; Testing MSE 98823.67420196533\n",
      "Epoch 9: Training R2 -46.72514153198028; Testing R2 -31.518304181726542\n",
      "Epoch 10: Training MSE 284247.78594970703; Testing MSE 53065.4486656189\n",
      "Epoch 10: Training R2 -23.420935256523254; Testing R2 -16.461386810227225\n",
      "Epoch 11: Training MSE 178331.05239868164; Testing MSE 38469.850158691406\n",
      "Epoch 11: Training R2 -14.321178563643791; Testing R2 -11.658649856806171\n",
      "Epoch 12: Training MSE 134458.09497833252; Testing MSE 29792.188453674316\n",
      "Epoch 12: Training R2 -10.551866345098958; Testing R2 -8.803232415706278\n",
      "Epoch 13: Training MSE 110600.5838394165; Testing MSE 25097.322130203247\n",
      "Epoch 13: Training R2 -8.502166176076933; Testing R2 -7.258368875344809\n",
      "Epoch 14: Training MSE 92364.44220542908; Testing MSE 22243.992805480957\n",
      "Epoch 14: Training R2 -6.93542175031317; Testing R2 -6.31947005721005\n",
      "Epoch 15: Training MSE 82301.85060501099; Testing MSE 19182.89532661438\n",
      "Epoch 15: Training R2 -6.070901743004742; Testing R2 -5.312204341261594\n",
      "Epoch 16: Training MSE 70492.54264831543; Testing MSE 17074.30863380432\n",
      "Epoch 16: Training R2 -5.056313910521736; Testing R2 -4.618365906048115\n",
      "Epoch 17: Training MSE 63415.983629226685; Testing MSE 15183.931112289429\n",
      "Epoch 17: Training R2 -4.448336651994525; Testing R2 -3.996330024875655\n",
      "Epoch 18: Training MSE 55316.00513458252; Testing MSE 13234.844636917114\n",
      "Epoch 18: Training R2 -3.752433077104641; Testing R2 -3.354975740141059\n",
      "Epoch 19: Training MSE 49271.88518047333; Testing MSE 11867.121124267578\n",
      "Epoch 19: Training R2 -3.233157046198012; Testing R2 -2.904921139560821\n",
      "Epoch 20: Training MSE 43873.77872467041; Testing MSE 10611.753749847412\n",
      "Epoch 20: Training R2 -2.7693827802893667; Testing R2 -2.4918377516897947\n",
      "Epoch 21: Training MSE 38753.48446369171; Testing MSE 10061.03069782257\n",
      "Epoch 21: Training R2 -2.3294765406543725; Testing R2 -2.310620246165431\n",
      "Epoch 22: Training MSE 34284.311866760254; Testing MSE 8424.769163131714\n",
      "Epoch 22: Training R2 -1.9455109302442994; Testing R2 -1.7722021926411893\n",
      "Epoch 23: Training MSE 30315.395963191986; Testing MSE 7470.528018474579\n",
      "Epoch 23: Training R2 -1.6045244982979998; Testing R2 -1.4582055308568562\n",
      "Epoch 24: Training MSE 27145.166957378387; Testing MSE 6836.595678329468\n",
      "Epoch 24: Training R2 -1.3321566519112413; Testing R2 -1.2496076940131973\n",
      "TRPTRANS_2_mean_norm\n",
      "tensor(11690.4609)\n",
      "tensor(2961.9233)\n",
      "Epoch 0: Training MSE 50997880000.0; Testing MSE 7114730675.0\n",
      "Epoch 0: Training R2 -4362348.805764449; Testing R2 -2402063.4218885563\n",
      "Epoch 1: Training MSE 15083209521.875; Testing MSE 1604992487.5\n",
      "Epoch 1: Training R2 -1290214.1251788484; Testing R2 -541874.093764131\n",
      "Epoch 2: Training MSE 3021072022.265625; Testing MSE 284173388.671875\n",
      "Epoch 2: Training R2 -258420.97655139506; Testing R2 -95941.18217911945\n",
      "Epoch 3: Training MSE 651031531.25; Testing MSE 109822254.4921875\n",
      "Epoch 3: Training R2 -55688.12421251568; Testing R2 -37077.02056010705\n",
      "Epoch 4: Training MSE 330811274.31640625; Testing MSE 72861219.7265625\n",
      "Epoch 4: Training R2 -28296.53900081463; Testing R2 -24598.292880553126\n",
      "Epoch 5: Training MSE 245699368.359375; Testing MSE 55789120.703125\n",
      "Epoch 5: Training R2 -21016.0813343411; Testing R2 -18834.43707990364\n",
      "Epoch 6: Training MSE 168482457.51953125; Testing MSE 44407879.296875\n",
      "Epoch 6: Training R2 -14410.960180208356; Testing R2 -14991.91987051145\n",
      "Epoch 7: Training MSE 128156562.74414062; Testing MSE 34787473.6328125\n",
      "Epoch 7: Training R2 -10961.49013869481; Testing R2 -11743.893314709367\n",
      "Epoch 8: Training MSE 93520853.02734375; Testing MSE 32271219.7265625\n",
      "Epoch 8: Training R2 -7998.757539700838; Testing R2 -10894.359543054514\n",
      "Epoch 9: Training MSE 70094996.31347656; Testing MSE 27556067.626953125\n",
      "Epoch 9: Training R2 -5994.913821381481; Testing R2 -9302.437147163568\n",
      "Epoch 10: Training MSE 54955631.640625; Testing MSE 25058053.076171875\n",
      "Epoch 10: Training R2 -4699.895194332452; Testing R2 -8459.061318634182\n",
      "Epoch 11: Training MSE 41274103.564453125; Testing MSE 26022665.087890625\n",
      "Epoch 11: Training R2 -3529.5796567914945; Testing R2 -8784.73214162369\n",
      "Epoch 12: Training MSE 30235255.57861328; Testing MSE 24856584.66796875\n",
      "Epoch 12: Training R2 -2585.318515605004; Testing R2 -8391.041864689181\n",
      "Epoch 13: Training MSE 26650677.06298828; Testing MSE 22256817.578125\n",
      "Epoch 13: Training R2 -2278.6942913944263; Testing R2 -7513.312500504861\n",
      "Epoch 14: Training MSE 19968750.18310547; Testing MSE 20395726.953125\n",
      "Epoch 14: Training R2 -1707.1234255743364; Testing R2 -6884.973947658258\n",
      "Epoch 15: Training MSE 15557473.217773438; Testing MSE 20816234.9609375\n",
      "Epoch 15: Training R2 -1329.7835594291287; Testing R2 -7026.945214151159\n",
      "Epoch 16: Training MSE 14356937.353515625; Testing MSE 19714678.271484375\n",
      "Epoch 16: Training R2 -1227.0899299241703; Testing R2 -6655.039339804244\n",
      "Epoch 17: Training MSE 11490253.454589844; Testing MSE 19677989.94140625\n",
      "Epoch 17: Training R2 -981.8742866529803; Testing R2 -6642.652682261628\n",
      "Epoch 18: Training MSE 10431762.265014648; Testing MSE 18182103.271484375\n",
      "Epoch 18: Training R2 -891.3311339719917; Testing R2 -6137.613726729178\n",
      "Epoch 19: Training MSE 9645759.899902344; Testing MSE 18602975.146484375\n",
      "Epoch 19: Training R2 -824.0966280517837; Testing R2 -6279.7078415019805\n",
      "Epoch 20: Training MSE 8626041.470336914; Testing MSE 16666973.681640625\n",
      "Epoch 20: Training R2 -736.8700905339657; Testing R2 -5626.078006184946\n",
      "Epoch 21: Training MSE 7650506.600952148; Testing MSE 16320058.49609375\n",
      "Epoch 21: Training R2 -653.4230070870248; Testing R2 -5508.953035095999\n",
      "Epoch 22: Training MSE 6285434.603881836; Testing MSE 16038475.610351562\n",
      "Epoch 22: Training R2 -536.6549853325093; Testing R2 -5413.885454529569\n",
      "Epoch 23: Training MSE 7217765.498352051; Testing MSE 15219247.216796875\n",
      "Epoch 23: Training R2 -616.4064082622534; Testing R2 -5137.298824978952\n",
      "Epoch 24: Training MSE 6400142.785644531; Testing MSE 15538456.0546875\n",
      "Epoch 24: Training R2 -546.4671032956891; Testing R2 -5245.069621608504\n",
      "TRPTRANS_3_mean_norm\n",
      "tensor(11467.2451)\n",
      "tensor(2919.1924)\n",
      "Epoch 0: Training MSE 3548643026.4648438; Testing MSE 130517732.2265625\n",
      "Epoch 0: Training R2 -309458.07148579357; Testing R2 -44709.219509690214\n",
      "Epoch 1: Training MSE 348505004.1015625; Testing MSE 71340053.90625\n",
      "Epoch 1: Training R2 -30390.34513477969; Testing R2 -24437.284481106148\n",
      "Epoch 2: Training MSE 250755366.84570312; Testing MSE 54443147.8515625\n",
      "Epoch 2: Training R2 -21866.097483584996; Testing R2 -18649.071907596983\n",
      "Epoch 3: Training MSE 181273639.55078125; Testing MSE 40432156.4453125\n",
      "Epoch 3: Training R2 -15806.950183177136; Testing R2 -13849.459696787124\n",
      "Epoch 4: Training MSE 135471555.078125; Testing MSE 29212919.091796875\n",
      "Epoch 4: Training R2 -11812.783842038538; Testing R2 -10006.19214800487\n",
      "Epoch 5: Training MSE 92451498.68164062; Testing MSE 21448727.807617188\n",
      "Epoch 5: Training R2 -8061.223989881506; Testing R2 -7346.486905591464\n",
      "Epoch 6: Training MSE 62636745.98388672; Testing MSE 14892648.095703125\n",
      "Epoch 6: Training R2 -5461.231368020957; Testing R2 -5100.632966496981\n",
      "Epoch 7: Training MSE 42677252.880859375; Testing MSE 10588101.5625\n",
      "Epoch 7: Training R2 -3720.66570477274; Testing R2 -3626.065357131029\n",
      "Epoch 8: Training MSE 28597602.10571289; Testing MSE 8833580.236816406\n",
      "Epoch 8: Training R2 -2492.851122345839; Testing R2 -3025.0356558979784\n",
      "Epoch 9: Training MSE 18126089.55078125; Testing MSE 5134867.767333984\n",
      "Epoch 9: Training R2 -1579.683884014413; Testing R2 -1758.0028658497624\n",
      "Epoch 10: Training MSE 12580091.793823242; Testing MSE 4146599.041748047\n",
      "Epoch 10: Training R2 -1096.0456866721868; Testing R2 -1419.4610378412265\n",
      "Epoch 11: Training MSE 8559682.080078125; Testing MSE 2887208.2275390625\n",
      "Epoch 11: Training R2 -745.4462469062059; Testing R2 -988.0434918021325\n",
      "Epoch 12: Training MSE 5846359.436035156; Testing MSE 2119332.6721191406\n",
      "Epoch 12: Training R2 -508.83120848026806; Testing R2 -724.9996581921972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training MSE 4078417.839050293; Testing MSE 1644220.736694336\n",
      "Epoch 13: Training R2 -354.65803271593285; Testing R2 -562.2450764037035\n",
      "Epoch 14: Training MSE 2852571.6705322266; Testing MSE 1335162.466430664\n",
      "Epoch 14: Training R2 -247.7582362965883; Testing R2 -456.37392105151355\n",
      "Epoch 15: Training MSE 2149336.072540283; Testing MSE 975821.2188720703\n",
      "Epoch 15: Training R2 -186.43264407235742; Testing R2 -333.2778038944847\n",
      "Epoch 16: Training MSE 1585722.7020263672; Testing MSE 750359.912109375\n",
      "Epoch 16: Training R2 -137.28279467486325; Testing R2 -256.04366609316776\n",
      "Epoch 17: Training MSE 1204948.892211914; Testing MSE 561194.0826416016\n",
      "Epoch 17: Training R2 -104.07745146267915; Testing R2 -191.24292511373244\n",
      "Epoch 18: Training MSE 904579.6272277832; Testing MSE 473391.9189453125\n",
      "Epoch 18: Training R2 -77.88377879635347; Testing R2 -161.16537208459772\n",
      "Epoch 19: Training MSE 752778.7567138672; Testing MSE 376519.9531555176\n",
      "Epoch 19: Training R2 -64.64599858300548; Testing R2 -127.98086312240883\n",
      "Epoch 20: Training MSE 608068.3952331543; Testing MSE 318464.27268981934\n",
      "Epoch 20: Training R2 -52.02654552328009; Testing R2 -108.09328023903464\n",
      "Epoch 21: Training MSE 470524.2286682129; Testing MSE 265548.2620239258\n",
      "Epoch 21: Training R2 -40.03201979723753; Testing R2 -89.96634520815067\n",
      "Epoch 22: Training MSE 407086.39850616455; Testing MSE 215185.16883850098\n",
      "Epoch 22: Training R2 -34.49992996103393; Testing R2 -72.71393886386498\n",
      "Epoch 23: Training MSE 343100.8441925049; Testing MSE 193805.3565979004\n",
      "Epoch 23: Training R2 -28.92007589322858; Testing R2 -65.39005970931534\n",
      "Epoch 24: Training MSE 318949.98302459717; Testing MSE 161504.70085144043\n",
      "Epoch 24: Training R2 -26.814002383758588; Testing R2 -54.325130951403246\n"
     ]
    }
   ],
   "source": [
    "for output_var in output_list:\n",
    "    print(output_var)\n",
    "    #     \n",
    "    y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images = \\\n",
    "        initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size)\n",
    "\n",
    "    # data set challenge for the concatenated datasets.\n",
    "    x_train_images_norm = x_train_images/255\n",
    "    x_test_images_norm = x_test_images/255\n",
    "\n",
    "    x_train_images_torch = torch.from_numpy(x_train_images_norm)\n",
    "    x_test_images_torch = torch.from_numpy(x_test_images_norm)\n",
    "    y_train_torch = torch.from_numpy(y_train)\n",
    "    y_test_torch = torch.from_numpy(y_test)\n",
    "\n",
    "    x_train_nhts_torch = torch.from_numpy(x_train)\n",
    "    x_test_nhts_torch = torch.from_numpy(x_test)\n",
    "\n",
    "    batch_size = 100\n",
    "    train_ds = TensorDataset(x_train_images_torch, x_train_nhts_torch, y_train_torch)\n",
    "    train_dl = DataLoader(train_ds, batch_size, shuffle = True)\n",
    "\n",
    "    batch_size = 100\n",
    "    test_ds = TensorDataset(x_test_images_torch, x_test_nhts_torch, y_test_torch)\n",
    "    test_dl = DataLoader(test_ds, batch_size, shuffle = True)    \n",
    "    \n",
    "    # model set up \n",
    "    num_x_nhts = x_train.shape[1]\n",
    "    input_channels = 4\n",
    "    use_pretrained = True\n",
    "    full_training = True\n",
    "    model_name = 'resnet_and_linear'\n",
    "    model = ResNet_And_Linear(num_categories, num_x_nhts, input_channels, use_pretrained, full_training)\n",
    "    model.to(device)\n",
    "\n",
    "    # training set up.\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    n_epoch = 25\n",
    "\n",
    "    # create baseline mse    \n",
    "    total_mse_train = criterion(y_train_torch.mean().repeat(y_train_torch.size()), y_train_torch)*y_train_torch.size()[0]\n",
    "    total_mse_test = criterion(y_test_torch.mean().repeat(y_test_torch.size()), y_test_torch)*y_test_torch.size()[0]\n",
    "    print(total_mse_train)\n",
    "    print(total_mse_test)\n",
    "    \n",
    "    # training here\n",
    "    model, mse_train_list, mse_test_list, r_square_train_list, r_square_test_list = \\\n",
    "        train_continuous_merged_model(model, train_dl, test_dl, criterion, optimizer, device, total_mse_train, total_mse_test, n_epoch)\n",
    "\n",
    "    # save models.\n",
    "    PATH = './models/'+model_name+'_'+output_var+'_'+image_type+'.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    model_dic[output_var]=model.state_dict()\n",
    "    \n",
    "    # save performance\n",
    "    performance[output_var] = {}\n",
    "    performance[output_var]['mse_train_list']=mse_train_list\n",
    "    performance[output_var]['mse_test_list']=mse_test_list\n",
    "    performance[output_var]['r_square_train_list']=r_square_train_list\n",
    "    performance[output_var]['r_square_test_list']=r_square_test_list\n",
    "    \n",
    "    # for i, (x_images_batch, x_nhts_batch, y_batch) in enumerate(train_concat_dl):\n",
    "    #     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "import pickle\n",
    "with open('outputs/performance_continuous_'+image_type+'_'+model_name+'.pickle', 'wb') as h:\n",
    "    pickle.dump(performance, h, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
