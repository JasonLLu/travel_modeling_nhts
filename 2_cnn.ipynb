{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Use Resnet to train models to fit five travel behavioral variables by using images. The default is using only the black and white images with resnet18 to fit continous outputs, but the codes leave the flexibility of using other models, images, and output types. Several functions are not useful yet: bottleneck_resnet18, return_bottleneck_resnet18, and train_discrete_model. \n",
    "\n",
    "#### To be done: adjustment along many dimensions - hyperparameters, model choice, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import util\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS choose devise first.\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size):\n",
    "    # outputs: randonmized training and testing sets for NHTS, BE, images, and y.\n",
    "    \n",
    "    ### read image array\n",
    "    if image_type == 'rgb':\n",
    "        image_array_ = np.load(\"data_process/image_array_rgb_tract_large.npy\", mmap_mode='r')\n",
    "        image_array = image_array_[:size,]\n",
    "    elif image_type == 'bw':\n",
    "        image_array_ = np.load(\"data_process/image_array_bw_tract_large.npy\", mmap_mode='r')\n",
    "        image_array = image_array_[:size,]        \n",
    "    elif image_type == 'merge':\n",
    "        bw_image_array_ = np.load(\"data_process/image_array_bw_tract_large.npy\", mmap_mode='r')\n",
    "        rgb_image_array_ = np.load(\"data_process/image_array_rgb_tract_large.npy\", mmap_mode='r')\n",
    "        bw_image_array = bw_image_array_[:size,]\n",
    "        rgb_image_array = rgb_image_array_[:size,]        \n",
    "        image_array = np.concatenate([rgb_image_array, bw_image_array], axis=1)\n",
    "    \n",
    "    ### create output array\n",
    "    df_ = pd.read_csv(\"data_process/df_merged_tract_large.csv\")\n",
    "    df = df_.iloc[:size,]\n",
    "    y_ = df[output_var].values \n",
    "    # cut y into categories for discrete variables\n",
    "    if output_type == 'continuous':\n",
    "        y = copy.deepcopy(y_)\n",
    "    elif output_type == 'discrete':\n",
    "        y = np.array(pd.qcut(y_, q = num_categories, labels=np.arange(num_categories))) \n",
    "    x = df[input_var]\n",
    "    BE = df[BE_var]\n",
    "            \n",
    "    ### randomization\n",
    "    shuffle_idx = np.arange(size)\n",
    "    np.random.seed(0) # important: don't change the seed number, unless the seed number across scripts are all changed.\n",
    "    np.random.shuffle(shuffle_idx)\n",
    "    train_ratio = 0.8\n",
    "\n",
    "    ###\n",
    "    # y\n",
    "    if output_type == 'discrete':\n",
    "        y_train = y[shuffle_idx[:int(train_ratio*size)]].astype(\"int\")\n",
    "        y_test = y[shuffle_idx[int(train_ratio*size):]].astype(\"int\")\n",
    "    elif output_type == 'continuous':\n",
    "        y_train = y[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "        y_test = y[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")\n",
    "    # BE\n",
    "    BE_train = BE.values[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "    BE_test = BE.values[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")        \n",
    "    # image array\n",
    "    x_train_images = image_array[shuffle_idx[:int(train_ratio*size)],].astype(\"float32\")\n",
    "    x_test_images = image_array[shuffle_idx[int(train_ratio*size):],].astype(\"float32\")\n",
    "    # NHTS\n",
    "    x_train = x.values[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "    x_test = x.values[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")\n",
    "    \n",
    "    return y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images\n",
    "\n",
    "# # test \n",
    "# image_type = 'bw'\n",
    "# output_var = 'HHFAMINC_mean'\n",
    "# output_type = 'continuous'\n",
    "# input_var=['R_AGE_IMP_mean', 'HHSIZE_mean', 'HHFAMINC_mean', 'HBHTNRNT_mean', 'HBPPOPDN_mean', 'HBRESDN_mean', \n",
    "#            'R_SEX_IMP_2_mean', 'EDUC_2_mean', 'HH_RACE_2_mean', 'HOMEOWN_1_mean', 'HOMEOWN_2_mean',\n",
    "#            'HBHUR_R_mean', 'HBHUR_S_mean', 'HBHUR_T_mean','HBHUR_U_mean']\n",
    "# BE_var = ['density', 'diversity', 'design']\n",
    "# num_categories = 1 # (1) certain category values can cause errors. (2) when output_type = 'continuous', this value needs to be 1.\n",
    "# size = 10000 # size needs to be smaller than the max\n",
    "# # \n",
    "# y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images = \\\n",
    "#     initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size)\n",
    "\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "# print(x_train_images.shape)\n",
    "# print(x_test_images.shape)\n",
    "# plt.figure()\n",
    "# plt.boxplot(y_train)\n",
    "# plt.figure()\n",
    "# plt.boxplot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_categories, input_channels = 3, use_pretrained=True, full_training=False):\n",
    "    # initliaze the CNN model.\n",
    "    # default input image size = 3*224*224, but inputs and output channels can be changed. \n",
    "    # num_categories: output channels. For continuous varialbes, use num_categories = 1.\n",
    "    # return the model\n",
    "\n",
    "    if model_name == 'resnet18':\n",
    "        \"\"\" resnet 18\"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        # train only the last layer.\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad=full_training\n",
    "        if input_channels != 3:\n",
    "            # Edit the input channels.\n",
    "            model_ft.conv1 = nn.Conv2d(input_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_categories) # if output_type == continuous, then num_categories = 1.\n",
    "\n",
    "    elif model_name == 'alexnet':\n",
    "        \"\"\" alexnet \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = full_training \n",
    "        if input_channels != 3:\n",
    "            model_ft.features[0] = nn.Conv2d(input_channels, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))    \n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_categories) # if output_type == continuous, then num_categories = 1.\n",
    "\n",
    "    elif model_name == 'vgg':\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = full_training \n",
    "        if input_channels != 3:\n",
    "            model_ft.features[0] = nn.Conv2d(input_channels, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_categories) # if output_type == continuous, then num_categories = 1.\n",
    "\n",
    "    elif model_name == 'squeezenet':\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = full_training \n",
    "        if input_channels != 3:\n",
    "            model_ft.features[0] = nn.Conv2d(input_channels, 96, kernel_size=(7, 7), stride=(2, 2))\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_categories, kernel_size=(1,1), stride=(1,1))\n",
    "\n",
    "    elif model_name == 'densenet':\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = full_training\n",
    "        if input_channels != 3:\n",
    "            model_ft.features[0] = nn.Conv2d(input_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_categories)\n",
    "\n",
    "    elif model_name == 'wide_resnet':\n",
    "        model_ft = models.wide_resnet50_2(pretrained=use_pretrained)\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = full_training \n",
    "        if input_channels != 3:\n",
    "            model_ft.conv1 = nn.Conv2d(input_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_categories)\n",
    "        \n",
    "    elif model_name == 'mnasnet':\n",
    "        model_ft = models.mnasnet1_0(pretrained=use_pretrained)\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = full_training\n",
    "        if input_channels != 3:\n",
    "            model_ft.layers[0] = nn.Conv2d(input_channels, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier[1] = nn.Linear(num_ftrs, num_categories)\n",
    "        \n",
    "    return model_ft\n",
    "\n",
    "# # test 1. initialize model for continuous var\n",
    "# model_name = 'resnet18'\n",
    "# num_categories = 1 \n",
    "# input_channels = 4\n",
    "# use_pretrained = True\n",
    "# full_training = True\n",
    "# model = initialize_model(model_name, num_categories, input_channels, use_pretrained, full_training)\n",
    "# model.to(device)\n",
    "\n",
    "# # test 2. initialize model for discrete var\n",
    "# model_name = 'resnet18'\n",
    "# # num_categories = 1 \n",
    "# input_channels = 4\n",
    "# use_pretrained = True\n",
    "# full_training = True\n",
    "# model = initialize_model(model_name, num_categories, input_channels, use_pretrained, full_training)\n",
    "# model.to(device)\n",
    "\n",
    "# # test 3. initialize model for continuous var\n",
    "# model_name = 'bottleneck_resnet18'\n",
    "# num_categories = 1 \n",
    "# input_channels = 4\n",
    "# use_pretrained = True\n",
    "# full_training = True\n",
    "# model = initialize_model(model_name, num_categories, input_channels, use_pretrained, full_training)\n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleneck_resnet18(nn.Module):\n",
    "    # This model does NOT work yet. It seems that the fc layer or the upsampling do not work...\n",
    "    # Goal: create a resnet architecture with bottleneck in the middle that reduces information into several nodes.\n",
    "    def __init__(self, num_categories, num_bottleneck, input_channels = 3, use_pretrained=True, full_training=False):\n",
    "        super(bottleneck_resnet18, self).__init__()\n",
    "        ref = models.resnet18(pretrained=use_pretrained)\n",
    "        self.sequence1 = nn.Sequential(ref.conv1, ref.bn1, ref.relu, ref.maxpool, ref.layer1,\n",
    "                                       ref.layer2)\n",
    "        ### condense \n",
    "        if num_bottleneck == 1:\n",
    "            self.condense = nn.AvgPool3d((128,28,28))\n",
    "        elif num_bottleneck == 2:\n",
    "            self.condense = nn.AvgPool3d((128,28,14))\n",
    "        elif num_bottleneck == 3:\n",
    "            self.condense = nn.AvgPool3d((128,28,9))\n",
    "\n",
    "        ### upsampling\n",
    "        self.upsample = nn.Sequential(nn.Conv2d(num_bottleneck, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "                                      nn.Upsample((28, 28)))\n",
    "        self.sequence2 = nn.Sequential(ref.layer3, ref.layer4, ref.avgpool)\n",
    "        self.fc = ref.fc\n",
    "        \n",
    "        ### edit parameters\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad=full_training\n",
    "        if input_channels != 3:\n",
    "            self.sequence1[0]=nn.Conv2d(input_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        num_ftrs=self.fc.in_features\n",
    "        self.fc=nn.Linear(num_ftrs, num_categories)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.sequence1(x)\n",
    "        x=self.condense(x)\n",
    "        x=self.upsample(x)\n",
    "        x=self.sequence2(x)\n",
    "        x=x.squeeze() # sw: this line is important, but I don't understand why resnet18 does not need it...\n",
    "        out=self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_bottleneck_renset(model,device,x_train_images,x_test_images,y_train,y_test):\n",
    "    # This function does not work yet.\n",
    "    # Goal: return the several nodes' values from the bottleneck resnet architecture.\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    bottleneck_train_list = []\n",
    "    def hook_train(module,inputs,outputs):\n",
    "        bottleneck_train_list.append(outputs)\n",
    "        \n",
    "    bottleneck_test_list = []\n",
    "    def hook_test(module,inputs,outputs):\n",
    "        bottleneck_test_list.append(outputs)\n",
    "\n",
    "    x_train_images_norm = x_train_images/255\n",
    "    x_test_images_norm = x_test_images/255\n",
    "\n",
    "    x_train_torch = torch.from_numpy(x_train_images_norm)\n",
    "    x_test_torch = torch.from_numpy(x_test_images_norm)\n",
    "    y_train_torch = torch.from_numpy(y_train)\n",
    "    y_test_torch = torch.from_numpy(y_test)\n",
    "\n",
    "    # create data loader: train and test. \n",
    "    train_ds = TensorDataset(x_train_torch, y_train_torch)\n",
    "    batch_size = 50\n",
    "    train_dl_no_shuffle = DataLoader(train_ds, batch_size, shuffle = False) # important: NO SHUFFLE.\n",
    "\n",
    "    test_ds = TensorDataset(x_test_torch, y_test_torch)\n",
    "    batch_size = 50\n",
    "    test_dl_no_shuffle = DataLoader(test_ds, batch_size, shuffle = False) # important: NO SHUFFLE.\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad=False # save space\n",
    "    \n",
    "    for inputs, labels in train_dl_no_shuffle:\n",
    "        # to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        bottleneck_train_list = model.layer3[1].conv1.register_forward_hook(hook_train)\n",
    "\n",
    "    for inputs, labels in test_dl_no_shuffle:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        bottleneck_test_list = model.layer3[1].conv1.register_forward_hook(hook_test)\n",
    "\n",
    "    return bottleneck_train_list,bottleneck_test_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discrete_model(model, train_dl, test_dl, criterion, optimizer, device, n_epoch = 25):\n",
    "    # Train a model with discrete outputs.\n",
    "    # Outputs: model; training and testing accuracy/log-loss.\n",
    "    # But so far this function is not used because of bad performance on discrete outputs.\n",
    "    log_loss_train_list=[]\n",
    "    log_loss_test_list=[]\n",
    "    accuracy_train_list=[]\n",
    "    accuracy_test_list=[]\n",
    "\n",
    "    # automatic model searching.\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # iterate\n",
    "    for epoch in range(n_epoch):\n",
    "    \n",
    "        running_log_loss_train = 0.0\n",
    "        running_log_loss_test = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "\n",
    "        # training    \n",
    "        for inputs, labels in train_dl:\n",
    "            # to device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward + backward\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # evaluate prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            # evaluate log loss\n",
    "            running_log_loss_train += loss.item()\n",
    "\n",
    "            # optimize\n",
    "            with torch.no_grad():\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # testing\n",
    "        for inputs, labels in test_dl:\n",
    "            # to device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward + backward\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # evaluate log loss\n",
    "            running_log_loss_test += loss.item()\n",
    "\n",
    "            # evaluate prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "        # print\n",
    "        print(\"Epoch {}: Training Loss {}; Testing Loss {}\".format(epoch, running_log_loss_train, running_log_loss_test))\n",
    "        print(\"Epoch {}: Training Accuracy {}; Testing Accuracy {}\".format(epoch, correct_train/total_train, correct_test/total_test))\n",
    "\n",
    "        # append loss here.\n",
    "        log_loss_train_list.append(running_log_loss_train)\n",
    "        log_loss_test_list.append(running_log_loss_test)\n",
    "        accuracy_train_list.append(correct_train/total_train)\n",
    "        accuracy_test_list.append(correct_test/total_test)\n",
    "        \n",
    "        if correct_test/total_test > best_acc:\n",
    "            best_acc = correct_test/total_test\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # load the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, log_loss_train_list, log_loss_test_list, accuracy_train_list, accuracy_test_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_continuous_model(model, train_dl, test_dl, criterion, optimizer, device, total_mse_train, total_mse_test, n_epoch = 25):\n",
    "    # This function trains the model with continous outputs.\n",
    "    # outputs: model, and R2 and MSE for training and testing\n",
    "    mse_train_list = []\n",
    "    mse_test_list = []\n",
    "    r_square_train_list = []\n",
    "    r_square_test_list = []\n",
    "\n",
    "    # automatic model searching.\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_r_square = 0.0\n",
    "    \n",
    "    for epoch in range(n_epoch): \n",
    "        running_mse_train = 0.0\n",
    "        running_mse_test = 0.0\n",
    "        \n",
    "        # training\n",
    "        for inputs, labels in train_dl:\n",
    "            # to device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward + backward\n",
    "            outputs = model(inputs)\n",
    "            # sw: be careful about the dimension matching at this point...\n",
    "            loss = criterion(outputs.view(-1), labels) # this .view(-1) seems specific to continuous variables\n",
    "            loss.backward()\n",
    "\n",
    "            # performance\n",
    "            running_mse_train += loss.item()*batch_size\n",
    "\n",
    "            # optimize\n",
    "            with torch.no_grad():\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # testing\n",
    "        for inputs, labels in test_dl:\n",
    "            # to device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward + backward        \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1), labels) # this .view(-1) is specific to continuous variables\n",
    "            running_mse_test += loss.item()*batch_size # this *batch_size is specific to continuous variables.\n",
    "\n",
    "        # R square for a batch\n",
    "        running_r_square_train = 1-running_mse_train/total_mse_train.item()\n",
    "        running_r_square_test = 1-running_mse_test/total_mse_test.item()\n",
    "        \n",
    "        print(\"Epoch {}: Training MSE {}; Testing MSE {}\".format(epoch, running_mse_train, running_mse_test))\n",
    "        print(\"Epoch {}: Training R2 {}; Testing R2 {}\".format(epoch, running_r_square_train, running_r_square_test))\n",
    "\n",
    "        mse_train_list.append(running_mse_train)\n",
    "        mse_test_list.append(running_mse_test)\n",
    "        r_square_train_list.append(running_r_square_train)\n",
    "        r_square_test_list.append(running_r_square_test)\n",
    "\n",
    "        # check overfitting for early stopping. This is designed in an ad-hoc way.\n",
    "        if epoch > 5 and running_r_square_test < 0.0:\n",
    "            break # break the for loop.\n",
    "        \n",
    "        # store the best performance.\n",
    "        if running_r_square_test > best_r_square:\n",
    "            best_r_square = running_r_square_test\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # load the weights of the best model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, mse_train_list, mse_test_list, r_square_train_list, r_square_test_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train resnet18 for continous outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up.\n",
    "output_list = ['HHVEHCNT_mean_norm', 'HHVEHCNT_P_CAP_mean_norm', 'TRPTRANS_1_mean_norm', 'TRPTRANS_2_mean_norm', 'TRPTRANS_3_mean_norm']\n",
    "input_var=['R_AGE_IMP_mean', 'HHSIZE_mean', 'HHFAMINC_mean', 'HBHTNRNT_mean', 'HBPPOPDN_mean', 'HBRESDN_mean', \n",
    "           'R_SEX_IMP_2_mean', 'EDUC_2_mean', 'HH_RACE_2_mean', 'HOMEOWN_1_mean', 'HOMEOWN_2_mean',\n",
    "           'HBHUR_R_mean', 'HBHUR_S_mean', 'HBHUR_T_mean','HBHUR_U_mean']\n",
    "BE_var = ['density', 'diversity', 'design']\n",
    "image_type = 'bw' # It can be 'rgb', 'bw', 'merge'\n",
    "output_type = 'continuous' \n",
    "num_categories = 1 # Certain category values can cause errors. When output_type = 'continuous', this value needs to be 1.\n",
    "size = 12000 # size needs to be smaller than the max (18491).\n",
    "\n",
    "model_name = 'resnet18' \n",
    "\n",
    "performance_continuous = {}\n",
    "model_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HHVEHCNT_mean_norm\n",
      "tensor(10700.4521)\n",
      "tensor(2549.4304)\n",
      "Epoch 0: Training MSE 12604.125246405602; Testing MSE 2297.4649310112\n",
      "Epoch 0: Training R2 -0.17790585589844254; Testing R2 0.09883207125079974\n",
      "Epoch 1: Training MSE 9714.341014623642; Testing MSE 2388.0933046340942\n",
      "Epoch 1: Training R2 0.09215602482347929; Testing R2 0.0632835922985201\n",
      "Epoch 2: Training MSE 9775.559794902802; Testing MSE 2275.9082436561584\n",
      "Epoch 2: Training R2 0.08643488524639154; Testing R2 0.10728756279377039\n",
      "Epoch 3: Training MSE 9565.040963888168; Testing MSE 2266.590929031372\n",
      "Epoch 3: Training R2 0.10610871099639718; Testing R2 0.1109422279895641\n",
      "Epoch 4: Training MSE 9386.626183986664; Testing MSE 2269.328820705414\n",
      "Epoch 4: Training R2 0.12278228491893062; Testing R2 0.10986830510363355\n",
      "Epoch 5: Training MSE 9397.053003311157; Testing MSE 2431.677985191345\n",
      "Epoch 5: Training R2 0.12180785699945096; Testing R2 0.046187742097365536\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-4d64f1cba05f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# training here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_test_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_square_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_square_test_list\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mtrain_continuous_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_mse_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_mse_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# save models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-2d85c098a04b>\u001b[0m in \u001b[0;36mtrain_continuous_model\u001b[0;34m(model, train_dl, test_dl, criterion, optimizer, device, total_mse_train, total_mse_test, n_epoch)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mrunning_mse_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for output_var in output_list:\n",
    "    print(output_var)\n",
    "\n",
    "    # data set up\n",
    "    y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images = \\\n",
    "        initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size)\n",
    "\n",
    "    # process data\n",
    "    x_train_images_norm = x_train_images/255 # very crude processing. It is improvable.\n",
    "    x_test_images_norm = x_test_images/255\n",
    "\n",
    "    x_train_torch = torch.from_numpy(x_train_images_norm)\n",
    "    x_test_torch = torch.from_numpy(x_test_images_norm)\n",
    "    y_train_torch = torch.from_numpy(y_train)\n",
    "    y_test_torch = torch.from_numpy(y_test)\n",
    "\n",
    "    # create data loader: train and test. \n",
    "    train_ds = TensorDataset(x_train_torch, y_train_torch)\n",
    "    batch_size = 100\n",
    "    train_dl = DataLoader(train_ds, batch_size, shuffle = True)\n",
    "\n",
    "    test_ds = TensorDataset(x_test_torch, y_test_torch)\n",
    "    batch_size = 100\n",
    "    test_dl = DataLoader(test_ds, batch_size, shuffle = True)\n",
    "\n",
    "    # model set up\n",
    "    input_channels = 4 # 4 for BW images; 3 for RGB images; 7 for merged images.\n",
    "    use_pretrained = True # unclear whether True or False is better.\n",
    "    full_training = True # Fully retraining the network seems to work better.\n",
    "#     num_bottleneck = 3 # Used for the bottleneck model\n",
    "    \n",
    "    if model_name == 'bottleneck_resnet18': # It does not work.\n",
    "        model = bottleneck_resnet18(num_categories, num_bottleneck, input_channels, use_pretrained, full_training)\n",
    "        model.to(device)\n",
    "    else: \n",
    "        # 'resnet18' and others works\n",
    "        model = initialize_model(model_name, num_categories, input_channels, use_pretrained, full_training)\n",
    "        model.to(device)\n",
    "    \n",
    "    # training set up\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    n_epoch = 25\n",
    "\n",
    "    # create baseline mse\n",
    "    total_mse_train = criterion(y_train_torch.mean().repeat(y_train_torch.size()), y_train_torch)*y_train_torch.size()[0]\n",
    "    total_mse_test = criterion(y_test_torch.mean().repeat(y_test_torch.size()), y_test_torch)*y_test_torch.size()[0]\n",
    "    print(total_mse_train)\n",
    "    print(total_mse_test)\n",
    "    \n",
    "    # training here.\n",
    "    model, mse_train_list, mse_test_list, r_square_train_list, r_square_test_list = \\\n",
    "        train_continuous_model(model, train_dl, test_dl, criterion, optimizer, device, total_mse_train, total_mse_test, n_epoch)\n",
    "\n",
    "    # save models.\n",
    "    PATH = './models/'+model_name+'_'+output_var+'_'+image_type+'.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    model_dic[output_var]=model.state_dict()\n",
    "    \n",
    "    # save performance\n",
    "    performance_continuous[output_var] = {}\n",
    "    performance_continuous[output_var]['mse_train_list']=mse_train_list\n",
    "    performance_continuous[output_var]['mse_test_list']=mse_test_list\n",
    "    performance_continuous[output_var]['r_square_train_list']=r_square_train_list\n",
    "    performance_continuous[output_var]['r_square_test_list']=r_square_test_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save performance\n",
    "import pickle\n",
    "with open('outputs/performance_continuous_'+image_type+'_'+model_name+'.pickle', 'wb') as h:\n",
    "    pickle.dump(performance_continuous, h, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# import pickle\n",
    "# with open('outputs/performance_continuous.pickle', 'rb') as h:\n",
    "#     performance_continuous = pickle.load(h)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store and save resnet's last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "def return_last_layer_resnet(model,device,x_train_images,x_test_images,y_train,y_test):\n",
    "    ###  \n",
    "    # \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    image_train_hidden_list = []\n",
    "    image_test_hidden_list = []\n",
    "\n",
    "    # return values in the last layer.\n",
    "    model_no_last_layer = nn.Sequential(*list(model.children())[:-1]).to(device)\n",
    "\n",
    "    # process data\n",
    "    x_train_images_norm = x_train_images/255\n",
    "    x_test_images_norm = x_test_images/255\n",
    "\n",
    "    x_train_torch = torch.from_numpy(x_train_images_norm)\n",
    "    x_test_torch = torch.from_numpy(x_test_images_norm)\n",
    "    y_train_torch = torch.from_numpy(y_train)\n",
    "    y_test_torch = torch.from_numpy(y_test)\n",
    "\n",
    "    # create data loader: train and test. \n",
    "    train_ds = TensorDataset(x_train_torch, y_train_torch)\n",
    "    batch_size = 100\n",
    "    train_dl_no_shuffle = DataLoader(train_ds, batch_size, shuffle = False) # important: NO SHUFFLE!!!\n",
    "\n",
    "    test_ds = TensorDataset(x_test_torch, y_test_torch)\n",
    "    batch_size = 100\n",
    "    test_dl_no_shuffle = DataLoader(test_ds, batch_size, shuffle = False)\n",
    "\n",
    "    for inputs, labels in train_dl_no_shuffle:\n",
    "        # to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        image_train_hidden_vector_batch = model_no_last_layer(inputs)\n",
    "        image_train_hidden_list.append(image_train_hidden_vector_batch.squeeze().cpu().detach().numpy())\n",
    "\n",
    "    for inputs, labels in test_dl_no_shuffle:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # forward + backward\n",
    "        image_test_hidden_vector_batch = model_no_last_layer(inputs)\n",
    "        image_test_hidden_list.append(image_test_hidden_vector_batch.squeeze().cpu().detach().numpy())\n",
    "\n",
    "    # vectorize\n",
    "    image_train_hidden_vector=np.array(image_train_hidden_list).reshape(-1,512) # 512, resnet architecture   \n",
    "    image_test_hidden_vector=np.array(image_test_hidden_list).reshape(-1,512) # 512, resnet architecture\n",
    "\n",
    "    # scale\n",
    "    scaler = MinMaxScaler()\n",
    "    image_train_hidden_vector_norm = scaler.fit_transform(image_train_hidden_vector)\n",
    "    image_test_hidden_vector_norm = scaler.fit_transform(image_test_hidden_vector)\n",
    "    \n",
    "    return image_train_hidden_vector_norm,image_test_hidden_vector_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HHVEHCNT_mean_norm\n",
      "HHVEHCNT_P_CAP_mean_norm\n",
      "TRPTRANS_1_mean_norm\n",
      "TRPTRANS_2_mean_norm\n",
      "TRPTRANS_3_mean_norm\n"
     ]
    }
   ],
   "source": [
    "# load model dictionary for all the output variables\n",
    "model_dic = {}\n",
    "model_name = 'resnet18'\n",
    "input_channels = 4 # for BW images\n",
    "use_pretrained = True # unclear True vs False is better\n",
    "full_training = True\n",
    "last_layer_dic_train = {}\n",
    "last_layer_dic_test = {}\n",
    "\n",
    "for output_var in output_list:\n",
    "    print(output_var)\n",
    "    # read models\n",
    "    model = initialize_model(model_name, num_categories, input_channels, use_pretrained, full_training)\n",
    "    PATH = './models/'+model_name+'_'+output_var+'_'+image_type+'.pth'\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model_dic[output_var]=model.state_dict()\n",
    "    \n",
    "    # initialize data. \n",
    "    y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images = \\\n",
    "        initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size)\n",
    "    \n",
    "    # obtain the last layer\n",
    "    image_train_hidden_vector_norm,image_test_hidden_vector_norm = \\\n",
    "        return_last_layer_resnet(model,device,x_train_images,x_test_images,y_train,y_test)\n",
    "\n",
    "    # \n",
    "    last_layer_dic_train[output_var]=image_train_hidden_vector_norm \n",
    "    last_layer_dic_test[output_var]=image_test_hidden_vector_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_process/last_layer_dic_train.pickle', 'wb') as h:\n",
    "    pickle.dump(last_layer_dic_train, h, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('data_process/last_layer_dic_test.pickle', 'wb') as h:\n",
    "    pickle.dump(last_layer_dic_test, h, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
